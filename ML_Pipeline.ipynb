{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"tags":["skip"],"colab":{"base_uri":"https://localhost:8080/"},"id":"OC32vu5mBk3C","executionInfo":{"status":"ok","timestamp":1679131465214,"user_tz":-60,"elapsed":57062,"user":{"displayName":"IDA MARUOTTO","userId":"00144866632806431806"}},"outputId":"78213179-22c2-4eda-faed-10edfbd59557"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.10\n","  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.20\n","  Downloading numpy-1.20.0-cp39-cp39-manylinux2010_x86_64.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (1.15.0)\n","Collecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (23.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (15.0.6.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (0.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (1.51.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (63.4.3)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (2.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (23.3.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (0.31.0)\n","Collecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (3.19.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (3.8.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10->-r requirements.txt (line 1)) (1.4.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.1.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10->-r requirements.txt (line 1)) (0.40.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2.27.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (3.4.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2.2.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2.16.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2.0.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10->-r requirements.txt (line 1)) (3.2.2)\n","Installing collected packages: keras, tensorflow-estimator, numpy, keras-preprocessing, tensorboard, tensorflow\n","\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.9 are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.10.0 requires numpy>=1.20.3, but you have numpy 1.20.0 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.20.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.10.0 keras-preprocessing-1.1.2 numpy-1.20.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]}],"source":["pip install --user -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["imports"],"id":"2-c3tnDnBk3E"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras.layers import Flatten, Dense, Reshape, Rescaling\n","from keras.callbacks import EarlyStopping\n","import os\n","from sklearn.metrics import mean_squared_error\n","from numpy import sqrt\n","import tensorflow\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pipeline-parameters"],"id":"j-IuTcp2Bk3F"},"outputs":[],"source":["learn_rate = 0.001\n","dense1_neurons = 65\n","dense2_neurons = 32\n","epochs = 15"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"0upm4jt1Bk3F"},"outputs":[],"source":["def read_data(patient):\n","    data = pd.read_csv(\"/Datasets/\" + patient + \"/\" + patient + \"-ws-training(t+30).csv\",  sep=',', header=0)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"Cuou-4bRBk3F"},"outputs":[],"source":["def remove_na(data):\n","    data.dropna(inplace = True)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"hP2RcVXoBk3F"},"outputs":[],"source":["def split(data):\n","    train, test = train_test_split(data, test_size=0.30)\n","    return train, test\n","\n","def get_label(train, test, val):\n","    y_train = train[\"var1(t+6)\"]\n","    train.drop(\"var1(t+6)\", axis = 1, inplace = True)\n","    y_test = test[\"var1(t+6)\"]\n","    test.drop(\"var1(t+6)\", axis = 1, inplace = True)\n","    y_val = val[\"var1(t+6)\"]\n","    val.drop(\"var1(t+6)\", axis = 1, inplace = True)\n","    return train.to_numpy(), y_train.to_numpy(), test.to_numpy(), y_test.to_numpy(), val.to_numpy(), y_val.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"aTmOL8BXBk3G"},"outputs":[],"source":["def clarke_error_grid(ref_values, pred_values, title_string):\n","\n","    #Checking to see if the lengths of the reference and prediction arrays are the same\n","    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {}) (prediction : {}).\".format(len(ref_values), len(pred_values))\n","\n","    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n","    if max(ref_values) > 400 or max(pred_values) > 400:\n","        print(\"Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<400 mg/dl).\".format(max(ref_values), max(pred_values)))\n","    if min(ref_values) < 0 or min(pred_values) < 0:\n","        print(\"Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mg/dl.\".format(min(ref_values),  min(pred_values)))\n","\n","    #Clear plot\n","    plt.clf()\n","\n","    #Set up plot\n","    plt.scatter(ref_values, pred_values, marker='o', color='black', s=8)\n","    plt.title(title_string + \" Clarke Error Grid\")\n","    plt.xlabel(\"Reference Concentration (mg/dl)\")\n","    plt.ylabel(\"Prediction Concentration (mg/dl)\")\n","    plt.xticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n","    plt.yticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n","    plt.gca().set_facecolor('white')\n","\n","    #Set axes lengths\n","    plt.gca().set_xlim([0, 400])\n","    plt.gca().set_ylim([0, 400])\n","    plt.gca().set_aspect((400)/(400))\n","\n","    #Plot zone lines\n","    plt.plot([0,400], [0,400], ':', c='black')                      #Theoretical 45 regression line\n","    plt.plot([0, 175/3], [70, 70], '-', c='black')\n","    #plt.plot([175/3, 320], [70, 400], '-', c='black')\n","    plt.plot([175/3, 400/1.2], [70, 400], '-', c='black')           #Replace 320 with 400/1.2 because 100*(400 - 400/1.2)/(400/1.2) =  20% error\n","    plt.plot([70, 70], [84, 400],'-', c='black')\n","    plt.plot([0, 70], [180, 180], '-', c='black')\n","    plt.plot([70, 290],[180, 400],'-', c='black')\n","    # plt.plot([70, 70], [0, 175/3], '-', c='black')\n","    plt.plot([70, 70], [0, 56], '-', c='black')                     #Replace 175.3 with 56 because 100*abs(56-70)/70) = 20% error\n","    # plt.plot([70, 400],[175/3, 320],'-', c='black')\n","    plt.plot([70, 400], [56, 320],'-', c='black')\n","    plt.plot([180, 180], [0, 70], '-', c='black')\n","    plt.plot([180, 400], [70, 70], '-', c='black')\n","    plt.plot([240, 240], [70, 180],'-', c='black')\n","    plt.plot([240, 400], [180, 180], '-', c='black')\n","    plt.plot([130, 180], [0, 70], '-', c='black')\n","\n","    #Add zone titles\n","    plt.text(30, 15, \"A\", fontsize=15)\n","    plt.text(370, 260, \"B\", fontsize=15)\n","    plt.text(280, 370, \"B\", fontsize=15)\n","    plt.text(160, 370, \"C\", fontsize=15)\n","    plt.text(160, 15, \"C\", fontsize=15)\n","    plt.text(30, 140, \"D\", fontsize=15)\n","    plt.text(370, 120, \"D\", fontsize=15)\n","    plt.text(30, 370, \"E\", fontsize=15)\n","    plt.text(370, 15, \"E\", fontsize=15)\n","\n","    #Statistics from the data\n","    zone = [0] * 5\n","    for i in range(len(ref_values)):\n","        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n","            zone[0] += 1    #Zone A\n","\n","        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n","            zone[4] += 1    #Zone E\n","\n","        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n","            zone[2] += 1    #Zone C\n","        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n","            zone[3] += 1    #Zone D\n","        else:\n","            zone[1] += 1    #Zone B\n","\n","    zone = [x/len(ref_values) for x in zone]\n","    return plt, zone"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"JtgVL66CBk3H"},"outputs":[],"source":["def plot(y_sc_test, y_pred):\n","    clarke_fig, zone = clarke_error_grid(y_sc_test*1, y_pred*1, 'Clarke Error Grid')\n","    print(\"Clarke Error Grid Zones\")\n","    print(zone)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"EGpa9rydBk3H"},"outputs":[],"source":["def define_model(train):\n","    multi_step_dense = keras.Sequential([\n","    Rescaling(scale=1/np.std(train), offset= np.mean(train) ),\n","    Flatten(),\n","    Dense(units= dense1_neurons, activation='relu'),\n","    Dense(units= dense2_neurons, activation='relu'),\n","    Dense(units=1),\n","    ])\n","    return multi_step_dense  "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"72CvW_IIBk3H"},"outputs":[],"source":["def prepare_dataset():\n","    #prepare dataset\n","    data = read_data(\"544\")\n","    data = remove_na(data)\n","    train, test = split(data)\n","    train, val = split(train)\n","    return get_label(pd.DataFrame(train, columns = data.columns), pd.DataFrame(test, columns = data.columns), pd.DataFrame(val, columns = data.columns))\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"77cWURpwBk3I"},"outputs":[],"source":["def compute():\n","    train, y_train, test, y_test, val, y_val = prepare_dataset()\n","    #define and train model\n","    model = define_model(train)\n","    earlystopping_cb = EarlyStopping(monitor=\"val_mse\", patience=5)\n","    model.compile(loss = \"mae\", optimizer = keras.optimizers.Adam(learning_rate=learn_rate), metrics = \"mse\")\n","    model.fit(train, y_train, batch_size = 1, epochs = epochs, validation_data=(val, y_val), shuffle = False, callbacks=[earlystopping_cb])\n","    y_pred = model.predict(test)\n","    #plot(y_test, y_pred)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["functions"],"id":"iOAppx58Bk3I"},"outputs":[],"source":["def metrics(model): \n","    train, y_train, test, y_test, val, y_val = prepare_dataset()\n","    y_pred = model.predict(test)\n","    mae = sqrt(mean_squared_error(y_test, y_pred))\n","    print('Test Set MAE: ', mae)\n","    return mae"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["block:compute"],"colab":{"base_uri":"https://localhost:8080/"},"id":"0r-7cAGJBk3I","executionInfo":{"status":"ok","timestamp":1679133167845,"user_tz":-60,"elapsed":325940,"user":{"displayName":"IDA MARUOTTO","userId":"00144866632806431806"}},"outputId":"ae8ffee9-5f0e-454b-9db1-d01a6290a19e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","6199/6199 [==============================] - 22s 3ms/step - loss: 45.5020 - mse: 3537.5291 - val_loss: 43.0927 - val_mse: 3100.0964\n","Epoch 2/15\n","6199/6199 [==============================] - 21s 3ms/step - loss: 44.8440 - mse: 3431.8884 - val_loss: 43.0174 - val_mse: 3073.8994\n","Epoch 3/15\n","6199/6199 [==============================] - 20s 3ms/step - loss: 44.6896 - mse: 3416.8921 - val_loss: 42.8744 - val_mse: 3082.1035\n","Epoch 4/15\n","6199/6199 [==============================] - 28s 5ms/step - loss: 44.5481 - mse: 3397.3154 - val_loss: 42.7368 - val_mse: 3066.4624\n","Epoch 5/15\n","6199/6199 [==============================] - 20s 3ms/step - loss: 44.4160 - mse: 3370.6089 - val_loss: 42.5400 - val_mse: 3071.6570\n","Epoch 6/15\n","6199/6199 [==============================] - 20s 3ms/step - loss: 44.2418 - mse: 3341.4380 - val_loss: 42.3767 - val_mse: 3024.9163\n","Epoch 7/15\n","6199/6199 [==============================] - 24s 4ms/step - loss: 44.0851 - mse: 3319.9817 - val_loss: 42.1320 - val_mse: 2984.4431\n","Epoch 8/15\n","6199/6199 [==============================] - 21s 3ms/step - loss: 43.8178 - mse: 3274.3093 - val_loss: 41.8862 - val_mse: 2896.8513\n","Epoch 9/15\n","6199/6199 [==============================] - 22s 3ms/step - loss: 43.4445 - mse: 3220.2500 - val_loss: 41.2282 - val_mse: 2834.2336\n","Epoch 10/15\n","6199/6199 [==============================] - 21s 3ms/step - loss: 42.7133 - mse: 3126.1272 - val_loss: 40.4819 - val_mse: 2656.1318\n","Epoch 11/15\n","6199/6199 [==============================] - 21s 3ms/step - loss: 42.7426 - mse: 3125.4963 - val_loss: 41.1669 - val_mse: 2720.9875\n","Epoch 12/15\n","6199/6199 [==============================] - 23s 4ms/step - loss: 42.0741 - mse: 3027.9856 - val_loss: 40.0265 - val_mse: 2561.8691\n","Epoch 13/15\n","6199/6199 [==============================] - 22s 4ms/step - loss: 40.6420 - mse: 2832.1836 - val_loss: 37.6562 - val_mse: 2249.1113\n","Epoch 14/15\n","6199/6199 [==============================] - 20s 3ms/step - loss: 37.3124 - mse: 2431.8042 - val_loss: 31.4768 - val_mse: 1636.8871\n","Epoch 15/15\n","6199/6199 [==============================] - 21s 3ms/step - loss: 32.9542 - mse: 1912.1340 - val_loss: 26.1530 - val_mse: 1339.5129\n","119/119 [==============================] - 0s 2ms/step\n"]}],"source":["model = compute()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["block:save","prev:compute"],"id":"eAeJz781Bk3I","outputId":"a89fcc5f-01a9-45ad-a8de-3eb6ca3803b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["export_path = 544/1\n","\n","INFO:tensorflow:Assets written to: 544/1/assets\n"]},{"name":"stderr","output_type":"stream","text":["[I 230309 17:26:10 builder_impl:779] Assets written to: 544/1/assets\n"]}],"source":["MODEL_DIR = '544'\n","version = 1\n","export_path = os.path.join(MODEL_DIR, str(version))\n","print('export_path = {}\\n'.format(export_path))\n","\n","tensorflow.saved_model.save(model, export_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["block:compute_mae","prev:compute"],"id":"qv1nm28EBk3J"},"outputs":[],"source":["mae = metrics(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pipeline-metrics"],"id":"Cy8oVW-NBk3J"},"outputs":[],"source":["print(mae)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"kubeflow_notebook":{"autosnapshot":true,"deploy_config":{},"docker_image":"gcr.io/arrikto/jupyter-kale-py38@sha256:2e1ce3427b780c0c78e7cfec527ee10c391092fdc4a8344cd76f8b83c61c5234","experiment_name":"new-experiment","katib_metadata":{"algorithm":{"algorithmName":"random","algorithmSettings":[{"name":"random_state","value":"12347"}]},"maxFailedTrialCount":10,"maxTrialCount":100,"objective":{"additionalMetricNames":[],"goal":500,"objectiveMetricName":"mae","type":"minimize"},"parallelTrialCount":3,"parameters":[{"feasibleSpace":{"list":["0.001","0.005","0.01"]},"name":"learn_rate","parameterType":"categorical"},{"feasibleSpace":{"max":"65","min":"64","step":"1"},"name":"dense1_neurons","parameterType":"int"},{"feasibleSpace":{"max":"33","min":"32","step":"1"},"name":"dense2_neurons","parameterType":"int"},{"feasibleSpace":{"list":["10","15"]},"name":"epochs","parameterType":"categorical"}]},"katib_run":true,"pipeline_description":"glucose-prediction with functions, with HP tuning grid search","pipeline_name":"glucose-prediction544","snapshot_volumes":true,"volume_access_mode":"rwm","volumes":[{"annotations":[],"mount_point":"/home/jovyan","name":"scc2-workspace-ffr9b","size":5,"size_type":"Gi","snapshot":false,"type":"clone"}]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}